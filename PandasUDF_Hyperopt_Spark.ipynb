{"cells":[{"cell_type":"markdown","source":["## Fitting and applying multiple models in parallel using Pandas UDFs, Hyperopt, and MLflow\nThis use case involves fitting multiple models in parallel to different groups of data. Each model is persisted in MLflow. Then, we apply the models to each group by loading each group's best model from MLflow and performing a prediction. Hyperopt is used for parameter tuning. The dataset is based on the Titanic survival classification dataset. In this case 500 records were randomly chosen from that dataset and assigned to other well known shipwrecks. We will build a separate model in parallel for each ship that estimates survival likelihood. This framework could easily be extended to large datasets with many groups."],"metadata":{}},{"cell_type":"code","source":["import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\n\nfrom pyspark.sql.types import StringType, DoubleType, StructType, StructField\nfrom pyspark.sql.functions import pandas_udf, PandasUDFType\nimport pyspark.sql.functions as func\n\nimport mlflow\nimport mlflow.sklearn\nfrom mlflow.tracking import MlflowClient\n\nfrom hyperopt import fmin, tpe, hp, Trials, STATUS_OK, SparkTrials\nfrom hyperopt.pyll.stochastic import sample\n\nclient = MlflowClient()\n\n# Enable Arrow-based columnar data transfers\nspark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\");"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"markdown","source":["### Import the features"],"metadata":{}},{"cell_type":"code","source":["features = spark.read.format(\"delta\").load(\"/mnt/databricks-datasets-private/ML/many_models\")\nfeatures.createOrReplaceTempView(\"features_table\")\n\ndisplay(features.limit(5))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name_prefix_Master</th><th>name_prefix_Miss</th><th>name_prefix_Mr</th><th>name_prefix_Mrs</th><th>name_prefix_None</th><th>name_parenths_no</th><th>name_parenths_yes</th><th>Sex_female</th><th>Sex_male</th><th>Embarked_C</th><th>Embarked_Q</th><th>Embarked_S</th><th>Embarked_nan</th><th>Pclass_1</th><th>Pclass_2</th><th>Pclass_3</th><th>ticket_text_1</th><th>ticket_text_2</th><th>ticket_text_3</th><th>ticket_text_4</th><th>ticket_text_5</th><th>ticket_text_6</th><th>ticket_text_7</th><th>ticket_text_8</th><th>ticket_length_3</th><th>ticket_length_4</th><th>ticket_length_5</th><th>ticket_length_6</th><th>ticket_length_7</th><th>cabin_chars_A</th><th>cabin_chars_B</th><th>cabin_chars_C</th><th>cabin_chars_D</th><th>cabin_chars_E</th><th>cabin_chars_F</th><th>cabin_chars_INFREQ</th><th>cabin_chars_NONE</th><th>SibSp</th><th>Parch</th><th>Survived</th><th>ship_name</th><th>Age</th><th>Fare</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>estonia</td><td>65</td><td>62</td></tr><tr><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>estonia</td><td>30</td><td>20</td></tr><tr><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>8</td><td>2</td><td>0</td><td>estonia</td><td>30</td><td>70</td></tr><tr><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>estonia</td><td>4</td><td>17</td></tr><tr><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>2</td><td>1</td><td>estonia</td><td>24</td><td>263</td></tr></tbody></table></div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["### View the groups. A model will be fit on each of these groups in parallel"],"metadata":{}},{"cell_type":"code","source":["%sql \n\nSELECT ship_name,\n       count(*) as count\nFROM features_table\nGROUP BY ship_name"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ship_name</th><th>count</th></tr></thead><tbody><tr><td>arizona</td><td>500</td></tr><tr><td>edmund_fitzgerald</td><td>500</td></tr><tr><td>titanic</td><td>500</td></tr><tr><td>estonia</td><td>500</td></tr></tbody></table></div>"]}}],"execution_count":6},{"cell_type":"markdown","source":["The data was partitioned by group. With large datasets, this could improve performance by avoiding constant shuffling."],"metadata":{}},{"cell_type":"code","source":["dbutils.fs.ls('/mnt/databricks-datasets-private/ML/many_models')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[4]: [FileInfo(path=&#39;dbfs:/mnt/databricks-datasets-private/ML/many_models/_delta_log/&#39;, name=&#39;_delta_log/&#39;, size=0),\n FileInfo(path=&#39;dbfs:/mnt/databricks-datasets-private/ML/many_models/ship_name=arizona/&#39;, name=&#39;ship_name=arizona/&#39;, size=0),\n FileInfo(path=&#39;dbfs:/mnt/databricks-datasets-private/ML/many_models/ship_name=edmund_fitzgerald/&#39;, name=&#39;ship_name=edmund_fitzgerald/&#39;, size=0),\n FileInfo(path=&#39;dbfs:/mnt/databricks-datasets-private/ML/many_models/ship_name=estonia/&#39;, name=&#39;ship_name=estonia/&#39;, size=0),\n FileInfo(path=&#39;dbfs:/mnt/databricks-datasets-private/ML/many_models/ship_name=titanic/&#39;, name=&#39;ship_name=titanic/&#39;, size=0)]</div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["Specify the label column name and features column names"],"metadata":{}},{"cell_type":"code","source":["label_col = 'Survived'\nfeature_cols = [column for column in features.columns if column not in [label_col, 'ship_name']]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["### Define the Hyperopt objective function"],"metadata":{}},{"cell_type":"code","source":["def config_objective(df, feature_cols, label_col, clf, scoring, cv):\n  \n  \"\"\"Configure the Hyperopt objective function\n\n  Arguments:\n  df: Pandas DataFrame:     The Pandas Dataframe on which to fit the model\n  features_cols: List[str]: List of column names that represent the model features\n  label_col: str            The label column name\n  clf: classifier           The model object that will be fit on the data, for instance a random forest\n  scoring: str              Scoring method to use for selecting the best model\n  cv: int                   The number of cross validation folds\n\n  \"\"\"\n\n  def objective(params):\n    \n    \"\"\"The Hyperopt objective function\"\"\"\n\n    params['n_estimators'] = int(params['n_estimators'])\n    params['min_samples_split'] = int(params['min_samples_split'])\n    params['max_features'] = int(params['max_features'])\n\n    clf_params = clf(**params)\n\n    scores = cross_val_score(clf_params, df[feature_cols], df[label_col], cv=cv, scoring=scoring, n_jobs=-1)\n\n    mean_score = scores.mean()\n    loss = 1 - mean_score\n\n    return {'loss': loss, 'params': params, 'status': STATUS_OK}  \n  \n  return objective"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["### Define the Pandas UDF with MLflow logging\nDefine a UDF that will fit a sklearn model to a group of data and perform hyperparameter tuning using Hyperopt; the models will be stored in MLFlow, and the model scores will be returned for each group."],"metadata":{}},{"cell_type":"code","source":["def fit_models_config(schema, feature_cols, label_col, grouping_col, clf, space, \n                      experiment_location=None, scoring='roc_auc', cv=5, max_evals=100, objective=config_objective, fit_best=True):\n  \n  \"\"\"Apply a scikit learn model to a group of data within a Spark DataFrame using a Pandas UDF\n\n  Arguments:\n  schema: Spark DataFrame schema: A Spark DataFrame schema that maps to the output of the function\n  features_cols: List[str]:       List of column names that represent the model features\n  label_col: str:                 Column to be predicted\n  grouping_col: str:              The column on which the DataFrame is being grouped\n  clf: classifier:                Classifier to fit to the data\n  space: Dict:                    Grid search data structure containing the parameters to search\n  experiment_location: str:       Path to the MLFlow experiment. If None, create a notebook experiment\n  scoring: str:                   Scoring method to use for validation\n  cv: int:                        Number of cross validation folds\n  max_evals: int:                 Max Hyperopt evaluations to run\n  objective: function:            The Hyperopt objective function\n  fit_best: boolean:              If True, a model with the best parameters will be fit and logged in MLFlow\n\n  \"\"\"\n  \n  \n  @pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n  def fit_models(data):\n    \"\"\"Fit the model; log the best model and its paramenters to \n    MLFlow\"\"\"\n\n    group_name = data[grouping_col].loc[0]\n    \n    # Specify features and label\n    features = data[feature_cols]\n    label = data[label_col]\n    \n    if experiment_location is not None:\n      mlflow.set_experiment(experiment_location)\n  \n    with mlflow.start_run() as run:\n      \n      # Configure and apply Hyperopt\n      bayes_trials = Trials()\n      \n      objective_config = config_objective(data, feature_cols, label_col, clf, scoring, cv)\n      \n      best_params = fmin(fn=objective_config, space=space, algo=tpe.suggest, max_evals=max_evals, trials=bayes_trials, rstate=np.random.RandomState(50))\n      \n      best_model_score = round(1 - bayes_trials.best_trial['result']['loss'], 4)\n\n      # Create model results output dataset\n      model_results_df = pd.DataFrame([(group_name, best_model_score)], \n                                        columns= ['group_name', 'best_model_score'])\n\n      # Log best model parameters and statistics to MLFlow\n      mlflow.set_tag(\"group_name\", group_name)\n\n      mlflow.set_tag(\"classifier_type\", clf.__name__)\n\n      mlflow.log_metric(\"roc_auc\", best_model_score)\n      \n      mlflow.log_params(best_params)\n      \n      # Fit the best model on the full dataset for the group\n      if fit_best:\n        \n        # Configure and fit best model\n        best_params_as_int = {param_name: int(value) for param_name, value in best_params.items()}\n        best_model_config = clf(**best_params_as_int)\n        best_model_config.fit(data[feature_cols], data[label_col])\n        \n        # Log the best model to MLFlow\n        mlflow.sklearn.log_model(sk_model=best_model_config, \n                                  artifact_path='survival_model')\n        \n      return model_results_df\n    \n  return fit_models"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["Configure the Pandas UDF"],"metadata":{}},{"cell_type":"code","source":["# Hyperopt search space\nspace = {'n_estimators':      hp.quniform('n_estimators', 10, 200, 10),\n         'min_samples_split': hp.quniform('min_samples_split', 2, 20, 1),\n         'max_features':      hp.quniform('max_features', 2, 15, 1)}\n\n\n# Pandas_UDF requires a Spark Schema that matches the output of the UDF\nfit_schema = StructType([StructField('group_name', StringType(), True),\n                         StructField('best_model_score', DoubleType(), True)])\n\n\nfit_models = fit_models_config(schema =        fit_schema, \n                               feature_cols =  feature_cols, \n                               label_col =     label_col,\n                               grouping_col =  \"ship_name\",\n                               clf =           RandomForestClassifier,\n                               space =         space\n                                )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["### Fit and store the best model for each group"],"metadata":{}},{"cell_type":"code","source":["best_model_stats = features.groupBy('ship_name').apply(fit_models)\n\ndisplay(best_model_stats)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>group_name</th><th>best_model_score</th></tr></thead><tbody><tr><td>arizona</td><td>0.8567</td></tr><tr><td>edmund_fitzgerald</td><td>0.8605</td></tr><tr><td>titanic</td><td>0.8647</td></tr><tr><td>estonia</td><td>0.8657</td></tr></tbody></table></div>"]}}],"execution_count":18},{"cell_type":"markdown","source":["### Create a Pandas UDF to apply the models  \nThe UDF will find the relevent model for each group within MLflow and preform a prediction for that group. In this example, the best model for each group is being chosen by the 'score' metric. A more production focused method for applying the models would be to register each group's best model in the Model Registry and then load the models from the registry. See the Model registry [documentation](https://docs.databricks.com/applications/mlflow/model-registry.html) and [example notebook](https://docs.databricks.com/_static/notebooks/mlflow/mlflow-model-registry-example.html)."],"metadata":{}},{"cell_type":"code","source":["def apply_models_config(schema, features_cols, grouping_col, score=\"roc_auc\", experiment_id=6649887):\n  \n  \"\"\"For each distinct group (values in groupBy statement), load the group's best model and \n  perform a prediction\n  \n  Arguments:\n  schema: Spark DataFrame schema: A Spark DataFrame schema that maps to the output of the function\n  features_cols: List[str]:       List of column names that represent the model features\n  grouping_col: str:              The column on which the DataFrame is being grouped\n  scoring: str                    Scoring method to use for selecting the best model\n  experiment_id: str              The id of the experiment from which to select models. Note, if\n                                  using the notebook experience (no external MLFlow experiment created)\n                                  then the experiment id is equal to the notebook id\n  \n  \"\"\"\n  \n  @pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n  def apply_models(data):\n    \n    \"\"\"Load the relvent model for the selected group and generate a\n    prediciton for the group\"\"\"\n  \n    group_name = data[grouping_col].loc[0]\n    \n    \n    def get_model_info(run_id):\n      \n      \"\"\"Get the ship name, run_id, and scoring metric of each run in \n      the experiment\"\"\"\n\n      data = client.get_run(run_id).data\n\n      fitted_model_group_name = data.tags['group_name']\n      metric = data.metrics[score]\n\n      return (fitted_model_group_name, run_id, metric)\n\n\n    # Get all of the runs in the MLFlow experiment\n    runs = client.list_run_infos(experiment_id)\n\n    # Get the run_ids for each run\n    run_ids = [run.run_id for run in runs]\n\n    # Get all relevent infor for each model run\n    models = [get_model_info(run_id) for run_id in run_ids]\n\n    # Filter to only models built using this group's data\n    models_for_group = [model for model in models if model[0] == group_name]\n\n    # Find the best model for this group by sorting descending by the scoring metric\n    best_model_for_group = sorted(models_for_group, key = lambda x: x[2], reverse=True)[0]\n  \n    best_model_run_id = best_model_for_group[1]\n\n    # Load the best model via its run_id\n    loaded_model = mlflow.sklearn.load_model(f\"runs:/{best_model_run_id}/survival_model\")\n\n    # Perform prediction; combine features and predictions\n    predictions = loaded_model.predict(data[features_cols])\n    predictions_df = pd.DataFrame(predictions, columns=['prediction'])\n\n    features_and_predictions = pd.concat([predictions_df, data], axis=1)\n    features_and_predictions['run_id'] = best_model_run_id\n\n    return features_and_predictions\n\n  return apply_models"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":20},{"cell_type":"markdown","source":["Configure the Pandas UDF"],"metadata":{}},{"cell_type":"code","source":["# Define the schema for the UDF's output DataFrame\nprediction_schema = StructType()\nprediction_schema.add('prediction', DoubleType())\nprediction_schema.add('run_id', StringType())\n\nfor column in features.schema:\n  prediction_schema.add(column.name, column.dataType)\n  \n\napply_models = apply_models_config(schema =        prediction_schema, \n                                   features_cols = feature_cols,\n                                   grouping_col =   \"ship_name\"\n                                    )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":22},{"cell_type":"markdown","source":["#### Apply the models to each group"],"metadata":{}},{"cell_type":"code","source":["predictions = features.groupBy('ship_name').apply(apply_models)\n\ndisplay(predictions.limit(5))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>prediction</th><th>run_id</th><th>name_prefix_Master</th><th>name_prefix_Miss</th><th>name_prefix_Mr</th><th>name_prefix_Mrs</th><th>name_prefix_None</th><th>name_parenths_no</th><th>name_parenths_yes</th><th>Sex_female</th><th>Sex_male</th><th>Embarked_C</th><th>Embarked_Q</th><th>Embarked_S</th><th>Embarked_nan</th><th>Pclass_1</th><th>Pclass_2</th><th>Pclass_3</th><th>ticket_text_1</th><th>ticket_text_2</th><th>ticket_text_3</th><th>ticket_text_4</th><th>ticket_text_5</th><th>ticket_text_6</th><th>ticket_text_7</th><th>ticket_text_8</th><th>ticket_length_3</th><th>ticket_length_4</th><th>ticket_length_5</th><th>ticket_length_6</th><th>ticket_length_7</th><th>cabin_chars_A</th><th>cabin_chars_B</th><th>cabin_chars_C</th><th>cabin_chars_D</th><th>cabin_chars_E</th><th>cabin_chars_F</th><th>cabin_chars_INFREQ</th><th>cabin_chars_NONE</th><th>SibSp</th><th>Parch</th><th>Survived</th><th>ship_name</th><th>Age</th><th>Fare</th></tr></thead><tbody><tr><td>0.0</td><td>9a7f7bc820994dbea89e70f978d7e9bd</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>arizona</td><td>30</td><td>8</td></tr><tr><td>1.0</td><td>9a7f7bc820994dbea89e70f978d7e9bd</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>arizona</td><td>3</td><td>26</td></tr><tr><td>0.0</td><td>9a7f7bc820994dbea89e70f978d7e9bd</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>2</td><td>2</td><td>0</td><td>arizona</td><td>9</td><td>34</td></tr><tr><td>0.0</td><td>9a7f7bc820994dbea89e70f978d7e9bd</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>arizona</td><td>36</td><td>0</td></tr><tr><td>1.0</td><td>9a7f7bc820994dbea89e70f978d7e9bd</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>arizona</td><td>3</td><td>16</td></tr></tbody></table></div>"]}}],"execution_count":24},{"cell_type":"markdown","source":["Confirm that different models were used for each group"],"metadata":{}},{"cell_type":"code","source":["display(\n  predictions.groupBy(['ship_name', 'run_id']).agg(func.count(\"*\").alias(\"count\"))\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ship_name</th><th>run_id</th><th>count</th></tr></thead><tbody><tr><td>estonia</td><td>ddb4bd4717b149eca5519f17adebecfe</td><td>500</td></tr><tr><td>arizona</td><td>9a7f7bc820994dbea89e70f978d7e9bd</td><td>500</td></tr><tr><td>titanic</td><td>59611a4ba7674058b0653f6546951803</td><td>500</td></tr><tr><td>edmund_fitzgerald</td><td>d264bc85b8e64657a61107a56b7f8757</td><td>500</td></tr></tbody></table></div>"]}}],"execution_count":26},{"cell_type":"markdown","source":["View the prediction for each group"],"metadata":{}},{"cell_type":"code","source":["display(\n  predictions.groupBy('ship_name').agg(func.sum(\"prediction\").alias(\"survived\"))\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ship_name</th><th>survived</th></tr></thead><tbody><tr><td>arizona</td><td>158.0</td></tr><tr><td>edmund_fitzgerald</td><td>165.0</td></tr><tr><td>titanic</td><td>163.0</td></tr><tr><td>estonia</td><td>164.0</td></tr></tbody></table></div>"]}}],"execution_count":28}],"metadata":{"name":"PandasUDF_Hyperopt_Spark","notebookId":551178164188491},"nbformat":4,"nbformat_minor":0}