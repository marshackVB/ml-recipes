{"cells":[{"cell_type":"markdown","source":["## Estimating and apply multiple models in parrallel using Pandas UDFs and MLFlow\nThis use case invovles fitting multiple models in parallel to different groups of data. Each model is persisted in MLFlow. Then, we will apply the models to each group by loading each group's best model from MLFlow and performing a prediction. The dataset is based on the Titanic survival classification dataset. In this case 500 records were randomly chosen from that dataset and assigned to other well known shipwrecks. We will build a separate model in parallel for each ship wreck that estimates survival likelihood. This framework could easily be extended to very large datasets with many groups."],"metadata":{}},{"cell_type":"code","source":["import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\n\nfrom pyspark.sql.types import StringType, DoubleType, StructType, StructField\nfrom pyspark.sql.functions import pandas_udf, PandasUDFType\nimport pyspark.sql.functions as func\n\nimport mlflow\nimport mlflow.sklearn\nfrom mlflow.tracking import MlflowClient\n\nclient = MlflowClient()\n\n# Enable Arrow-based columnar data transfers\nspark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["%sql\n\nSELECT *\nFROM default.workshop_many_models\nLIMIT 5"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name_prefix_Master</th><th>name_prefix_Miss</th><th>name_prefix_Mr</th><th>name_prefix_Mrs</th><th>name_prefix_None</th><th>name_parenths_no</th><th>name_parenths_yes</th><th>Sex_female</th><th>Sex_male</th><th>Embarked_C</th><th>Embarked_Q</th><th>Embarked_S</th><th>Embarked_nan</th><th>Pclass_1</th><th>Pclass_2</th><th>Pclass_3</th><th>ticket_text_1</th><th>ticket_text_2</th><th>ticket_text_3</th><th>ticket_text_4</th><th>ticket_text_5</th><th>ticket_text_6</th><th>ticket_text_7</th><th>ticket_text_8</th><th>ticket_length_3</th><th>ticket_length_4</th><th>ticket_length_5</th><th>ticket_length_6</th><th>ticket_length_7</th><th>cabin_chars_A</th><th>cabin_chars_B</th><th>cabin_chars_C</th><th>cabin_chars_D</th><th>cabin_chars_E</th><th>cabin_chars_F</th><th>cabin_chars_INFREQ</th><th>cabin_chars_NONE</th><th>Age</th><th>Fare</th><th>SibSp</th><th>Parch</th><th>Survived</th><th>ship_name</th></tr></thead><tbody><tr><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>29.69911764705882</td><td>110.8833</td><td>0.0</td><td>0.0</td><td>1.0</td><td>edmund_fitzgerald</td></tr><tr><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>45.0</td><td>35.5</td><td>0.0</td><td>0.0</td><td>0.0</td><td>edmund_fitzgerald</td></tr><tr><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>47.0</td><td>38.5</td><td>0.0</td><td>0.0</td><td>0.0</td><td>edmund_fitzgerald</td></tr><tr><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>29.69911764705882</td><td>15.5</td><td>1.0</td><td>0.0</td><td>0.0</td><td>edmund_fitzgerald</td></tr><tr><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>50.0</td><td>55.9</td><td>1.0</td><td>0.0</td><td>0.0</td><td>edmund_fitzgerald</td></tr></tbody></table></div>"]}}],"execution_count":3},{"cell_type":"code","source":["%sql \n\nSELECT ship_name,\n       count(*) as count\nFROM default.workshop_many_models\nGROUP BY ship_name"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ship_name</th><th>count</th></tr></thead><tbody><tr><td>arizona</td><td>500</td></tr><tr><td>edmund_fitzgerald</td><td>500</td></tr><tr><td>titanic</td><td>500</td></tr><tr><td>estonia</td><td>500</td></tr></tbody></table></div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["Notice that the table is partitioned by 'ship_name', the column we will group by when applying each model. This will improve perfomance on large datasets by mitigating the need to shuffle the data into groups before estimating and applying models"],"metadata":{}},{"cell_type":"code","source":["%sql\n\nSHOW PARTITIONS default.workshop_many_models"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ship_name</th></tr></thead><tbody><tr><td>arizona</td></tr><tr><td>edmund_fitzgerald</td></tr><tr><td>titanic</td></tr><tr><td>estonia</td></tr></tbody></table></div>"]}}],"execution_count":6},{"cell_type":"markdown","source":["We can see the partition folder structure in within the file system"],"metadata":{}},{"cell_type":"code","source":["dbutils.fs.ls('dbfs:/user/hive/warehouse/workshop_many_models')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[34]: [FileInfo(path=&#39;dbfs:/user/hive/warehouse/workshop_many_models/_delta_log/&#39;, name=&#39;_delta_log/&#39;, size=0),\n FileInfo(path=&#39;dbfs:/user/hive/warehouse/workshop_many_models/ship_name=arizona/&#39;, name=&#39;ship_name=arizona/&#39;, size=0),\n FileInfo(path=&#39;dbfs:/user/hive/warehouse/workshop_many_models/ship_name=edmund_fitzgerald/&#39;, name=&#39;ship_name=edmund_fitzgerald/&#39;, size=0),\n FileInfo(path=&#39;dbfs:/user/hive/warehouse/workshop_many_models/ship_name=estonia/&#39;, name=&#39;ship_name=estonia/&#39;, size=0),\n FileInfo(path=&#39;dbfs:/user/hive/warehouse/workshop_many_models/ship_name=titanic/&#39;, name=&#39;ship_name=titanic/&#39;, size=0)]</div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["Set our Spark environment such that each task with have four cores to use. The idea is that each model fitting will have four cores available that sklearn can use to parrallelize its grid search."],"metadata":{}},{"cell_type":"code","source":["spark.conf.set('spark.task.cpus', 4)\nspark.conf.set('spark.executor.cores', 4)\n\nprint(spark.conf.get('spark.task.cpus'), spark.conf.get('spark.executor.cores'))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">4 4\n</div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["### Define the Pandas UDF\nDefine a UDF that will fit an sklearn model to a group of data; the models will be stored in MLFlow, and the model scores will be returned for each group."],"metadata":{}},{"cell_type":"code","source":["def fit_models_config(schema, features_cols, label_col, grouping_col, classifier, param_grid, scoring, experiment_location, cv=5):\n  \n  \"\"\"Apply a scikit learn model to a group of data within a Spark DataFrame using a Pandas UDF\n  \n  Arguments:\n  schema: Spark DataFrame schema: A Spark DataFrame schema that maps to the output of the function\n  features_cols: List[str]:       List of column names that represent the model features\n  label_col: str:                 Column to be predicted\n  grouping_col: str:                 The column on which the DataFrame is being grouped\n  classier: sklearn classifier:   Classifier to use\n  param_grid: Dict                Grid search data structure containing the parameters to search\n  scoring: str                    Scoring method to use for validation\n  experiment_location: str        Path to the MLFlow experiment\n  cv: int                         Number of cross validation folds\n\n  \"\"\"\n\n  @pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n  def fit_models(data):\n    \"\"\"Fit the model; log the best model and its paramenters to \n    MLFlow\"\"\"\n\n    # Specify features and label\n    features = data[features_cols]\n    label = data[label_col]\n\n    # Create and fit model\n    clf = classifier\n    grid_search = GridSearchCV(clf, param_grid, scoring=scoring, n_jobs=-1, cv=cv)\n    grid_search.fit(features, label)\n\n    # Log metrics and artifacts to MLFlow\n    mlflow.set_experiment(experiment_location)\n\n    with mlflow.start_run() as run:\n\n      group_name = data[grouping_col].loc[0]\n\n      best_model_score = grid_search.best_score_\n\n      model_results_df = pd.DataFrame([(group_name, best_model_score)], \n                                        columns= ['group_name', 'best_model_score'])\n\n      mlflow.set_tag(\"group_name\", group_name)\n\n      mlflow.set_tag(\"classifier_type\", type(clf).__name__)\n\n      mlflow.log_metric(scoring, best_model_score)\n      \n      best_params = grid_search.best_params_\n      \n      mlflow.log_params(best_params)\n\n      mlflow.sklearn.log_model(sk_model=grid_search.best_estimator_, \n                               artifact_path='survival_model')\n\n      return model_results_df\n    \n  return fit_models"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["Specify the features DataFrame, label column name and features column names"],"metadata":{}},{"cell_type":"code","source":["spark_features = spark.table('default.workshop_many_models')\n\nlabel_col = 'Survived'\nfeatures_cols = [column for column in spark_features.columns if column not in [label_col, 'ship_name']]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["Configure the Pandas UDF"],"metadata":{}},{"cell_type":"code","source":["# Pandas_UDF requires a Spark Schema that matches the output of the UDF\nfit_schema = StructType([StructField('group_name', StringType(), True),\n                         StructField('best_model_score', DoubleType(), True)])\n\nfit_models = fit_models_config(schema =        fit_schema, \n                               features_cols = features_cols, \n                               label_col =     label_col,\n                               grouping_col =  \"ship_name\",\n                               classifier =    RandomForestClassifier(n_jobs=-1),\n                               param_grid =    {'n_estimators':       [20, 50, 100], \n                                                 'min_samples_split': [2, 5, 10],\n                                                 'max_features':      [2, 5, 10]},\n                                scoring =       \"roc_auc\",\n                                experiment_location = \"/Users/marshall.carter@databricks.com/workshops/ml/pandas_udf/survival_prediction\"\n                                )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["### Fit and store a model for each ship"],"metadata":{}},{"cell_type":"code","source":["best_model_stats = spark_features.groupBy('ship_name').apply(fit_models)\n\ndisplay(best_model_stats)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>group_name</th><th>best_model_score</th></tr></thead><tbody><tr><td>arizona</td><td>0.8531899665365668</td></tr><tr><td>edmund_fitzgerald</td><td>0.8598849504471425</td></tr><tr><td>titanic</td><td>0.8519684377522335</td></tr><tr><td>estonia</td><td>0.8543395821245747</td></tr></tbody></table></div>"]}}],"execution_count":18},{"cell_type":"markdown","source":["A View of the models populated in MLFlow by our Pandas_UDF. At this point we have estimated only one model per group, but we could easily fit many models. Note: the below image is from an older model run.\n\n<img src=\"files/marshall.carter/workshop_many_models.png\"\n     alt=\"Markdown Monster icon\"\n     style=\"float: left; margin-right: 10px;\" />"],"metadata":{}},{"cell_type":"markdown","source":["### Create a Pandas UDF to apply the models  \nThe UDF will find the relevent model for each group within MLFlow and preform a prediction for that group. In this example, the best model for each group is being chosen by the 'score' metric. A more production focused method for applying the models would be to register each group's best model in the Model Registry and then load the model's from the registry. See the Model registry [documentation](https://docs.databricks.com/applications/mlflow/model-registry.html) and [example notebook](https://docs.databricks.com/_static/notebooks/mlflow/mlflow-model-registry-example.html)."],"metadata":{}},{"cell_type":"code","source":["def apply_models_config(schema, features_cols, grouping_col, score=\"roc_auc\", experiment_id=\"3007990057292469\"):\n  \n  \"\"\"For each distinct group (values in groupBy statement), load the group's best model and \n  perform a prediction\n  \n  Arguments:\n  schema: Spark DataFrame schema: A Spark DataFrame schema that maps to the output of the function\n  features_cols: List[str]:       List of column names that represent the model features\n  grouping_col: str:              The column on which the DataFrame is being grouped\n  scoring: str                    Scoring method to use for selecting the best model\n  experiment_id: str              The id of the experiment from which to select models\n  \n  \"\"\"\n  \n  @pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n  def apply_models(data):\n    \"\"\"Load the relvent model for the selected group and generate a\n    prediciton for the group\"\"\"\n  \n    group_name = data[grouping_col].loc[0]\n    \n    \n    def get_model_info(run_id):\n      \"\"\"Get the ship name, run_id, and scoring metric of each run in \n      the experiment\"\"\"\n\n      data = client.get_run(run_id).data\n\n      fitted_model_group_name = data.tags['group_name']\n      metric = data.metrics[score]\n\n      return (fitted_model_group_name, run_id, metric)\n\n\n    # Get all of the runs in the MLFlow experiment\n    runs = client.list_run_infos(experiment_id)\n\n    # Get the run_ids for each run\n    run_ids = [run.run_id for run in runs]\n\n    # Get all relevent infor for each model run\n    models = [get_model_info(run_id) for run_id in run_ids]\n\n    # Filter to only models built using this group's data\n    models_for_group = [model for model in models if model[0] == group_name]\n\n    # Find the best model for this group by sorting descending by the scoring metric\n    best_model_for_group = sorted(models_for_group, key = lambda x: x[2], reverse=True)[0]\n  \n    best_model_run_id = best_model_for_group[1]\n\n    # Load the best model via its run_id\n    loaded_model = mlflow.sklearn.load_model(f\"runs:/{best_model_run_id}/survival_model\")\n\n    # Perform prediction; combine features and predictions\n    predictions = loaded_model.predict(data[features_cols])\n    predictions_df = pd.DataFrame(predictions, columns=['prediction'])\n\n    features_and_predictions = pd.concat([predictions_df, data], axis=1)\n    features_and_predictions['run_id'] = best_model_run_id\n\n    return features_and_predictions\n\n  return apply_models"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":21},{"cell_type":"markdown","source":["Configure the Pandas UDF"],"metadata":{}},{"cell_type":"code","source":["prediction_schema = StructType()\nprediction_schema.add('prediction', DoubleType())\nprediction_schema.add('run_id', StringType())\n\nfor column in spark_features.schema:\n  prediction_schema.add(column.name, column.dataType)\n  \n\napply_models = apply_models_config(schema =        prediction_schema, \n                                   features_cols = features_cols,\n                                   grouping_col =  \"ship_name\"\n                                    )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark/python/pyspark/sql/types.py:1624: DeprecationWarning: Using or importing the ABCs from &#39;collections&#39; instead of from &#39;collections.abc&#39; is deprecated, and in 3.8 it will stop working\n  arrow_type = pa.struct(fields)\n</div>"]}}],"execution_count":23},{"cell_type":"markdown","source":["#### Apply the models to each ship"],"metadata":{}},{"cell_type":"code","source":["predictions = spark_features.groupBy('ship_name').apply(apply_models)\n\ndisplay(predictions.limit(5))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>prediction</th><th>run_id</th><th>name_prefix_Master</th><th>name_prefix_Miss</th><th>name_prefix_Mr</th><th>name_prefix_Mrs</th><th>name_prefix_None</th><th>name_parenths_no</th><th>name_parenths_yes</th><th>Sex_female</th><th>Sex_male</th><th>Embarked_C</th><th>Embarked_Q</th><th>Embarked_S</th><th>Embarked_nan</th><th>Pclass_1</th><th>Pclass_2</th><th>Pclass_3</th><th>ticket_text_1</th><th>ticket_text_2</th><th>ticket_text_3</th><th>ticket_text_4</th><th>ticket_text_5</th><th>ticket_text_6</th><th>ticket_text_7</th><th>ticket_text_8</th><th>ticket_length_3</th><th>ticket_length_4</th><th>ticket_length_5</th><th>ticket_length_6</th><th>ticket_length_7</th><th>cabin_chars_A</th><th>cabin_chars_B</th><th>cabin_chars_C</th><th>cabin_chars_D</th><th>cabin_chars_E</th><th>cabin_chars_F</th><th>cabin_chars_INFREQ</th><th>cabin_chars_NONE</th><th>Age</th><th>Fare</th><th>SibSp</th><th>Parch</th><th>Survived</th><th>ship_name</th></tr></thead><tbody><tr><td>1.0</td><td>c441321fa1034754997c2e74b38793b5</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>49.0</td><td>89.1042</td><td>1.0</td><td>0.0</td><td>1.0</td><td>arizona</td></tr><tr><td>1.0</td><td>c441321fa1034754997c2e74b38793b5</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.92</td><td>151.55</td><td>1.0</td><td>2.0</td><td>1.0</td><td>arizona</td></tr><tr><td>0.0</td><td>c441321fa1034754997c2e74b38793b5</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>70.5</td><td>7.75</td><td>0.0</td><td>0.0</td><td>0.0</td><td>arizona</td></tr><tr><td>0.0</td><td>c441321fa1034754997c2e74b38793b5</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>28.5</td><td>7.2292</td><td>0.0</td><td>0.0</td><td>0.0</td><td>arizona</td></tr><tr><td>1.0</td><td>c441321fa1034754997c2e74b38793b5</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>27.0</td><td>21.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>arizona</td></tr></tbody></table></div>"]}}],"execution_count":25},{"cell_type":"markdown","source":["Confirm that different models were used for each ship"],"metadata":{}},{"cell_type":"code","source":["display(\n  predictions.groupBy(['ship_name', 'run_id']).agg(func.count(\"*\").alias(\"count\"))\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ship_name</th><th>run_id</th><th>count</th></tr></thead><tbody><tr><td>arizona</td><td>c441321fa1034754997c2e74b38793b5</td><td>500</td></tr><tr><td>titanic</td><td>5433df0b91024b3b8e9f93c0033ae736</td><td>500</td></tr><tr><td>edmund_fitzgerald</td><td>3097ca31e1d84534992ff96fcd64044d</td><td>500</td></tr><tr><td>estonia</td><td>3a4e66eee0f6420faf8716a418c024fe</td><td>500</td></tr></tbody></table></div>"]}}],"execution_count":27},{"cell_type":"markdown","source":["View the prediction for each ship"],"metadata":{}},{"cell_type":"code","source":["display(\n  predictions.groupBy('ship_name').agg(func.sum(\"prediction\").alias(\"survived\"))\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ship_name</th><th>survived</th></tr></thead><tbody><tr><td>arizona</td><td>169.0</td></tr><tr><td>edmund_fitzgerald</td><td>167.0</td></tr><tr><td>titanic</td><td>163.0</td></tr><tr><td>estonia</td><td>169.0</td></tr></tbody></table></div>"]}}],"execution_count":29}],"metadata":{"name":"PandasUDF_Spark","notebookId":1937615162608041},"nbformat":4,"nbformat_minor":0}